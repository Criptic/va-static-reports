"A ConvNet for the 2020s"
"A Generalist Agent"
"A Systematic Evaluation of Large Language Models of Code"
"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection & Multi-Task Learning Challenges"
"ActionFormer: Localizing Moments of Actions with Transformers"
"Alibaba Group"
"AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models"
"Anhui University"
"Asia"
"Australia"
"BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning"
"Benchmarking Generalization via In-Context Instructions on 1, 600+ Language Tasks"
"BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers"
"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"
"BigScience Team"
"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"
"Block-NeRF: Scalable Large Scene Neural View Synthesis"
"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
"Can language models learn from explanations in context?"
"Canada"
"Carnegie Mellon University"
"Chain of Thought Prompting Elicits Reasoning in Large Language Models"
"China"
"Chinese University of Hong Kong"
"City University of Hong Kong"
"Classifier-Free Diffusion Guidance"
"CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields"
"CMT: Convolutional Neural Networks Meet Vision Transformers"
"ColabFold: making protein folding accessible to all"
"Competition-Level Code Generation with AlphaCode"
"Conditional Prompt Learning for Vision-Language Models"
"Cornell University"
"Data Analytics for the Identification of Fake Reviews Using Supervised Learning"
"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language"
"Deep Reinforcement Learning-Based Path Control and Optimization for Unmanned Ships"
"DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection"
"DeepMind"
"DeepMind, New York University"
"Denmark"
"Denoising Diffusion Restoration Models"
"Detecting Twenty-thousand Classes using Image-level Supervision"
"Diffusion Models: A Comprehensive Survey of Methods and Applications"
"Diffusion-LM Improves Controllable Text Generation"
"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"
"Discovering faster matrix multiplication algorithms with reinforcement learning"
"DN-DETR: Accelerate DETR Training by Introducing Query DeNoising"
"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"
"Dr. Babasaheb Ambedkar Marathwada University"
"DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation"
"Duke University"
"EleutherAI"
"Ensemble unsupervised autoencoders and Gaussian mixture model for cyberattack detection"
"EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction"
"Equivariant Diffusion for Molecule Generation in 3D"
"ETH Zurich"
"Europe"
"European Molecular Biology Laboratory"
"Exploring Plain Vision Transformer Backbones for Object Detection"
"Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution"
"Flamingo: a Visual Language Model for Few-Shot Learning"
"France"
"Genetic Algorithm-Based Trajectory Optimization for Digital Twin Robots"
"GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation"
"Germany"
"Google"
"Google, Boston University"
"GPT-NeoX-20B: An Open-Source Autoregressive Language Model"
"Hierarchical Text-Conditional Image Generation with CLIP Latents"
"Hong Kong University of Science and Technology"
"How Do Vision Transformers Work?"
"Hugging Face"
"HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video"
"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"
"Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network"
"India"
"Instant Neural Graphics Primitives with a Multiresolution Hash Encoding"
"Ireland"
"Israel"
"Japan"
"Johns Hopkins University"
"LAION"
"LAION-5B: An open large-scale dataset for training next generation image-text models"
"LaMDA: Language Models for Dialog Applications"
"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"
"Language-driven Semantic Segmentation"
"Large Language Models are Zero-Shot Reasoners"
"Learning robust perceptive locomotion for quadrupedal robots in the wild"
"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"
"Magnetic control of tokamak plasmas through deep reinforcement learning"
"Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors"
"Masked Autoencoders As Spatiotemporal Learners"
"Max Planck Institute for Multidisciplinary Sciences"
"Measuring and Improving the Use of Graph Information in Graph Neural Networks"
"Megvii"
"Meta"
"Meta, UC Berkeley"
"Microsoft"
"Mila, University of Montreal"
"MIT"
"Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"
"Nanjing University, 4Paradigm Inc."
"Nanjing University, Shanghai AI Lab"
"Nanjing University, Tencent"
"Nanyang Technological University"
"National University of Ireland Galway"
"NELA-GT-2021: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles"
"Netherlands"
"Ningbo University of Technology"
"North America"
"NVIDIA"
"OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
"Omnivore: A Single Model for Many Visual Modalities"
"Online reinforcement learning multiplayer non-zero sum games of continuous-time Markov jump linear systems"
"OpenAI"
"OPT: Open Pre-trained Transformer Language Models"
"Outracing champion Gran Turismo drivers with deep reinforcement learning"
"Overview of The Shared Task on Homophobia and Transphobia Detection in Social Media Comments"
"PaLM: Scaling Language Modeling with Pathways"
"Patches Are All You Need?"
"Peking University"
"PETR: Position Embedding Transformation for Multi-View 3D Object Detection"
"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"
"Protein structure predictions to atomic accuracy with AlphaFold"
"Quantifying Memorization Across Neural Language Models"
"Queen Mary University of London"
"Red Teaming Language Models with Language Models"
"Rensselaer Polytechnic Institute"
"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"
"Robust Speech Recognition via Large-Scale Weak Supervision"
"Salesforce"
"Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs"
"ShanghaiTech University"
"SignalP 6.0 predicts all five types of signal peptides using protein language models"
"Singapore"
"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"
"Solving Quantitative Reasoning Problems with Language Models"
"Sony"
"South Korea"
"Stanford University"
"Swin Transformer V2: Scaling Up Capacity and Resolution"
"Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images"
"Switzerland"
"Technical University of Denmark, ETH Zurich"
"Technion"
"TensoRF: Tensorial Radiance Fields"
"Text and Code Embeddings by Contrastive Pre-Training"
"Tongji University"
"Torsional Diffusion for Molecular Conformer Generation"
"Training Compute-Optimal Large Language Models"
"Training language models to follow instructions with human feedback"
"Transformer Memory as a Differentiable Search Index"
"Tsinghua University"
"UC Berkeley"
"Unified Contrastive Learning in Image-Text-Label Space"
"UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models"
"United Kingdom"
"United States"
"University of Amsterdam"
"University of Hong Kong"
"University of Notre Dame"
"University of Science and Technology of China"
"University of Sydney"
"University of Texas at Arlington"
"University of Tokyo"
"University of Washington"
"University of Washington, Meta"
"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"
"Video Diffusion Models"
"VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"
"Vision-Language Pre-Training with Triple Contrastive Learning"
"Visual Prompt Tuning"
"ViTAEv2: Vision Transformer Advanced by Exploring Inductive Bias for Image Recognition and Beyond"
"VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance"
"What Makes Good In-Context Examples for GPT-3?"
"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality"
"Wuhan University"
"Wuhan University of Science and Technology"
"Yonsei University, NAVER"
