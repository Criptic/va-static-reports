"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity"
"AI Is a Lot of Work: As the technology becomes ubiquitous, a vast tasker underclass is emerging â€” and not going anywhere"
"An investigation of licensing of datasets for machine learning based on the GQM model"
"Automatic Android Deprecated-API Usage Update by Learning from Single Updated Example"
"Bridging the Gap Between Ethics and Practice: Guidelines for Reliable, Safe, and Trustworthy Human-centered AI Systems"
"Carbon Emissions and Large Neural Network Training"
"Cheaply Evaluating Inference Efficiency Metrics for Autoregressive Transformer APIs"
"Datasheets for Datasets"
"DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models"
"Downstream"
"Ecosystem Graphs: The Social Footprint of Foundation Models"
"Energy and Policy Considerations for Deep Learning in NLP"
"Ethical and social risks of harm from Language Models"
"Evaluating a Methodology for Increasing AI Transparency: A Case Study"
"Expert explainer: Allocating accountability in AI supply chains"
"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"
"Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass"
"Holistic Evaluation of Language Models"
"Identifying Terms and Conditions Important to Consumers using Crowdsourcing"
"Interactive Model Cards: A Human-Centered Approach to Model Documentation"
"Machine Learning and Artificial Intelligence: Legal Concepts"
"Meta Platform Terms"
"Model"
"Model Cards for Model Reporting"
"On AI Deployment: AI supply chains (and why they matter)"
"Outsider Oversight: Designing a Third Party Audit Ecosystem for AI Governance"
"ProPILE: Probing Privacy Leakage in Large Language Models"
"Putting the Semantics into Semantic Versioning"
"Redesigning Data Privacy: Reimagining Notice & Consent for human technology interaction"
"Robust Distortion-free Watermarks for Language Models"
"Scaling Instruction-Finetuned Language Models"
"Structured access: an emerging paradigm for safe AI deployment"
"The future of crowd work"
"The ROOTS Search Tool: Data Transparency for LLMs"
"The Time Is Now to Develop Community Norms for the Release of Foundation Models"
"Thinking Upstream: Ethics and Policy Opportunities in AI Supply Chains"
"Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure"
"Towards Responsible AI: A Design Space Exploration of Human-Centered Artificial Intelligence User Interfaces to Investigate Fairness"
"Training Compute-Optimal Large Language Models"
"Upstream"
"Watch out for This Commit! A Study of Influential Software Changes"
"What Does it Mean for a Language Model to Preserve Privacy?"
